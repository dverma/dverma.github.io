---
layout: post
title:  "The Big O"
date:   2017-02-13
excerpt: "The Big O - What, Why & When?"
tag:
- markdown
- syntax
- sample
- test
- jekyll
comments: true
image:
  feature: bigO.png
---

# Motivation for this post
It's been a while since I brushed up my knowledge of the basic algorithms and raw implementations of various data structures and as a software engineer that's *bad*, like *real real bad*.
In the corporate world making enterprise level software built upon frameworks that do most of the heavy lifting when it comes to the efficiency, we tend to ignore the basics. Well, its time I touch up on those again, so here goes.
A little humor before we start though, like seriously, what would life be like if it was all business.
![Who better than Randall Munroe](http://imgs.xkcd.com/comics/1337_part_2.png)


# The Big O - What, Why & When?

## What is The Big O?
Big O notation is used in Computer Science to describe the performance or complexity of an algorithm; specifically the worst-case scenario, and can be used to describe the execution time required or the space used (e.g. in memory or on disk) by an algorithm.

## Why is it important?


## When is it important?
>When is it not?
